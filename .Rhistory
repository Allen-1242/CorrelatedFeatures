#Creating clusters based upon graph theory
list1 = list()
#Data Cleaning
Data <- DataCleaning(Data)
#note to add all data checks that are needed in the system
#If any NA values drop it
Data[is.na(Data), ] <- 0
#If any value is not a numeric or factor , we drop it
class_check <- as.data.table(sapply(Data, class))
if(any(class_check$V1 %in% 'character'))
{
print('Please convert all chracter variables to factors or dummies')
break
}
Data <- as.data.table(Data)
###Correlation matrix creation
#Examine this further of course
cor_matrix <- GeneralCor(Data[, -Y_var, with = FALSE])
cor_matrix[cor_matrix == 'NULL'] <- 0
ut <- upper.tri(cor_matrix)
pairs_mat_total <- data.frame(
var1 = rownames(cor_matrix)[row(cor_matrix)[ut]],
var2 = colnames(cor_matrix)[col(cor_matrix)[ut]],
value = unlist((cor_matrix)[ut])
)
#Sub-setting values only above threshold values
pairs_mat = pairs_mat_total[which(abs(pairs_mat_total$value) >= corr_cutoff & (pairs_mat_total$var1 != pairs_mat_total$var2)),]
rownames(pairs_mat) <- NULL
##Start of Random Forest iterations
list1 = list()
if(dim(pairs_mat)[1] != 0)
{
for(j in 1:nrow(pairs_mat))
{
list1[[j]] = c(pairs_mat[j,1], pairs_mat[j,2])
list1[[j]] = sort(list1[[j]])
}
i = rep(1:length(list1), lengths(list1))
j = factor(unlist(list1))
tab = sparseMatrix(i = i , j = as.integer(j), x = TRUE, dimnames= list(NULL, levels(j)))
connects = tcrossprod(tab, boolArith = TRUE)
group = clusters(graph_from_adjacency_matrix(as(connects, "lsCMatrix")))$membership
var_groups <- tapply(list1, group, function(x) sort(unique(unlist(x))))
var_groups <- as.list(var_groups)
#Condition to extract the focus variables
for(i in 1:length(var_groups))
{
if(any(var_groups[[i]] %in% Focus_variables))
{
if(sum(which(var_groups[[i]] %in% Focus_variables >= 2)))
{
Intersection <- dplyr::intersect(Focus_variables, var_groups[[i]])
var_groups[[i]] <- Intersection[1]
next
}
var_groups[[i]] <- dplyr::intersect(Focus_variables, var_groups[[i]])
}
}
#Getting every combination of variables possible
if(fast_calculation == TRUE)
{
result <- purrr::map(var_groups, 1)
result <- as.data.frame(t(unlist(result)))
}else
{
result <- expand.grid(var_groups)
}
RF_list <- list()
noncor_columns = colnames(Data)[! colnames(Data) %in% unlist(var_groups)]
Data_nocor <- Data[, ..noncor_columns]
##Start of the RF, note we need to add multiprocessing here
for(i in 1:nrow(result))
{
Data_temp <- cbind(Data_nocor, Data[, unlist(result[i,]), with = FALSE])
Rf <- ranger(as.formula(paste(paste(Y_var, '~'), paste(colnames(Data_temp), collapse = "+"))), data = Data_temp, mtry = ncol(Data_temp/3), importance = 'permutation')
Rf_2 <- data.frame(Rf$variable.importance)
RF_list[[i]] <- Rf_2
print(i)
}
}else
{
Rf <- ranger(as.formula(paste(paste(Y_var, '~'), paste(colnames(Data_temp), collapse = "+"))), data = Data_temp, mtry = ncol(Data_temp/3), importance = 'permutation')
Rf_2 <- data.frame(Rf$variable.importance)
RF_list[[i]] <- Rf_2
}
#Fast Aggregation across multiple frames
l <- lapply(RF_list, function(x) {x$RowName <- row.names(x) ; x})
Res <- Reduce(function(...) merge(..., by = "RowName", all = TRUE), l)
Rf_2 <- dcast(melt(setDT(Res), "RowName"),
RowName ~ sub("\\..*", "", variable),
mean,
na.rm = TRUE,
value.var = "value")
#Taking the best variable from each group
if(dim(pairs_mat)[1] != 0)
{
for(bv in 1:nrow(var_groups))
{
comp <- var_groups[bv]
comp <- unlist(comp[[1]])
temp <- Rf_2[which(Rf_2$RowName %in% comp)]
keep_var <- Rf_2$RowName[Rf_2$Rf == max(temp$Rf)]
rem_var <- comp[which(comp != keep_var)]
#Dropping all values not needed
Rf_2 <- Rf_2[!(Rf_2$RowName %in% unlist(rem_var))]
}
#Fitting the RF without the correlated variables
temp_var <- c(Rf_2$RowName, Y_var)
Data_temp <- Data[,c(..temp_var)]
Rf_list = list()
#Here let us add RFE in order to run it
Rf <- ranger(as.formula(paste(paste(Y_var, '~'), paste(colnames(Data_temp), collapse = "+"))), data = Data_temp, mtry = ncol(Data_temp)/3, importance = 'permutation')
Rf_2 <- data.frame(Rf$variable.importance)
Rf_2$Var <- rownames(Rf_2)
##Simple 95%optimization
#To ADD: RFE with cv based methods
# #Final RF based on RFE , based on num_features or coverage methods
# if(#Method is based on coverage)
Rf_2 <- na.omit(Rf_2)
Rf_2 <- Rf_2[which(Rf_2$Rf.variable.importance  >= 0),]
Rf_2 <- Rf_2[order(-Rf_2$Rf.variable.importance),]
Rf_2$Rf.variable.importance <- Rf_2$Rf.variable.importance/sum(Rf_2$Rf.variable.importance)
x1 <- cumsum(Rf_2$Rf.variable.importance)
temp <- which(x1 > RF_coverage)[1]
final_variables <- Rf_2[0:temp,]$Var
# if(#method is based on num_columns)
# {
#   Rf_2 <- na.omit(Rf_2)
#   Rf_2 <- Rf_2[which(Rf_2$Rf >= 0)]
#   Rf_2 <- Rf_2[order(-Rf)]
#
#   Rf_2 <- Rf_2$Rf/sum(Rf_2$Rf)
#   Rf_2 <- cumsum(Rf_2$Rf)
#   temp <- which(Rf_2$Rf > Rf_info_cutoff)[1]
# }
}
##Plotting function for correlation methods
if(plot == TRUE)
{
heatmap <- ggplot(data = pairs_mat, aes(x=var1, y=var2, fill=value)) +
geom_tile() +
geom_text(aes(var2, var1, label = value), size = 5) +
scale_fill_gradient2(low = "red", high = "green",
limit = c(-1,1), name="Correlation") +
theme(axis.title.x = element_blank(),
axis.title.y = element_blank(),
panel.background = element_blank())
igraph_plot <- graph_from_adjacency_matrix(as(connects, "lsCMatrix"))
}else
{
heatmap <- c()
igraph_plot <- c()
}
Results <- list('Final_Variables' = final_variables, 'Variable_groups' = var_groups,
'Correlation_heatmap' = heatmap,'Graph_plot' = igraph_plot)
return(Results)
}
library(TangledFeatures)
version()
R
install.packages(c("roxygen2", "testthat"))
install.packages(c("boot", "foreign", "Matrix"), lib="C:/Users/sunny/AppData/Local/Temp/RtmpG8yjxN/renv-system-library")
library(TangledFeatures)
devtools::document()
library(roxygen2)
detach("package:roxygen2", unload = TRUE)
?tcrossprod
library(TangledFeatures)
library(MASS)
devtools::document()
library(TangledFeatures)
library(TangledFeatures)
library(TangledFeatures)
renv::record("renv@0.16.0")
devtools::document()
devtools::document()
devtools::document()
devtools::document()
library(TangledFeatures)
devtools::document()
library(TangledFeatures)
renv::snapshot()
library(TangledFeatures)
library(TangledFeatures)
library(TangledFeatures)
library(TangledFeatures)
devtools::document()
library(TangledFeatures)
ggplot2::ggplot()
library(TangledFeatures)
devtools::document()
devtools::document()
library(TangledFeatures)
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
library(TangledFeatures)
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::use_testthat()
devtools::uses_testthat()
usethis::use_test("report_p")
usethis::use_test("report_p")
usethis::use_test("report_p")
usethis::use_test("DataCleaning")
library(TangledFeatures)
devtools::document()
library(TangledFeatures)
df_tot <- read.csv("C:\\Users\\sunny\\Downloads\\housingPrices\\train.csv")
class(df_tot)
!is.data.frame(df_tot)
if(!is.data.frame(df_tot)) stop("Value needs to be a data frame or data table")
if(is.data.frame(df_tot)) stop("Value needs to be a data frame or data table")
rm(df_tot)
library(TangledFeatures)
usethis::use_pkgdown
usethis::use_pkgdown()
devtools::document()
library(TangledFeatures)
devtools::document()
library(TangledFeatures)
devtools::document()
devtools::uses_testthat()
devtools::document()
usethis::use_vignette("Correlation")
devtools::document()
usethis::use_pkgdown_github_pages()
pkgdown::build_site()
devtools::document()
pkgdown::build_site()
library(TangledFeatures)
pkgdown::build_site()
usethis::use_pkgdown_github_pages()
gitcreds::gitcreds_set()
usethis::create_github_token()
usethis::use_pkgdown_github_pages()
gh_token_help()
usethis::gh_token_help()
usethis::use_pkgdown_github_pages()
credentials::set_github_pat("227G!t^8aEi")
devtools::install_github(build_vignettes=TRUE, repo = 'https://github.com/Allen-1242/TangledFeatures')
usethis::use_pkgdown_github_pages()
pkgdown::build_site()
usethis::use_pkgdown_github_pages()
use_github_pages()
usethis::use_github_pages()
usethis::use_github_pages(branch = "TangledFeatures", path = "/", cname = NA)
usethis::use_github_pages(branch = "TangledFeatures", path = "/", cname = NA)
git clone https://github.com/USERNAME/REPO.git
devtools::install_github(build_vignettes=TRUE, repo = 'https://github.com/Allen-1242/TangledFeatures')
git
gitcreds::gitcreds_get()
where git
git
gitcreds::gitcreds_approve()
git
usethis::use_pkgdown_github_pages()
gitcreds::gitcreds_approve()
usethis::use_github_pages(branch = "TangledFeatures", path = "/", cname = NA)
use_github_pages()
usethis::use_github_pages()
gh_token_help()
gitcreds::gitcreds_set()
git
where git
git_sitrep()
usethis::git_sitrep()
credentials::git_credentials_forget()
library(credentials)
credentials::git_credentials_forget()
library(credentials)
library(gitcreds)
library(credentials)
library(credentials)
detach("package:credentials", unload = TRUE)
library(credentials)
library(polycor)
devtools::check()
Data = TangledFeatures::Housing_Prices_dataset[1:100,]
list1 = list()
Results <- list()
var1 <- NULL
var2 <- NULL
temp_var <- NULL
value <- NULL
corr_cutoff = 0.7
RF_coverage = 0.95
fast_calculation = FALSE
cor1 = 'pearson'
cor2 = 'polychoric'
cor3 = 'spearman'
plot = FALSE
RF_coverage = 0.95
num_features = 5
Focus_variables = list()
corr_cutoff = 0.7
colnames(Data)
Y_var <- 'SalePrice'
DataCleanRes <- DataCleaning(Data, Y_var = Y_var)
Y_var <- DataCleanRes$New_Dependent
Data <- DataCleanRes$Cleaned_Data
#If any NA values drop it
Data[is.na(Data), ] <- 0
#If any value is not a numeric or factor , we drop it
class_check <- data.table::as.data.table(vapply(Data, class, 'character'))
if(any(class_check$V1 %in% 'character'))
{
print('Please convert all chracter variables to factors or dummies')
return(Results)
}
Da
Data <- as.data.table(Data) #Redundant steps?
#Examine this further of course
cor_matrix <- GeneralCor(Data[, -Y_var, with = FALSE])
cor_matrix[cor_matrix == 'NULL'] <- 0
ut <- upper.tri(cor_matrix)
pairs_mat_total <- data.frame(
var1 = rownames(cor_matrix)[row(cor_matrix)[ut]],
var2 = colnames(cor_matrix)[col(cor_matrix)[ut]],
value = unlist((cor_matrix)[ut])
)
#Sub-setting values only above threshold values
pairs_mat = pairs_mat_total[which(abs(pairs_mat_total$value) >= corr_cutoff & (pairs_mat_total$var1 != pairs_mat_total$var2)),]
rownames(pairs_mat) <- NULL
##Start of Random Forest iterations
list1 = list()
if(dim(pairs_mat)[1] != 0)
{
for(j in seq(nrow(pairs_mat)))
{
list1[[j]] = c(pairs_mat[j,1], pairs_mat[j,2])
list1[[j]] = sort(list1[[j]])
}
i = rep(1:length(list1), lengths(list1))
j = factor(unlist(list1))
tab = Matrix::sparseMatrix(i = i , j = as.integer(j), x = TRUE, dimnames= list(NULL, levels(j)))
connects = Matrix::tcrossprod(tab, boolArith = TRUE)
group = igraph::clusters(igraph::graph_from_adjacency_matrix(as(connects, "lMatrix")))$membership
var_groups <- tapply(list1, group, function(x) sort(unique(unlist(x))))
var_groups <- as.list(var_groups)
#Condition to extract the focus variables
for(i in seq(length(var_groups)))
{
if(any(var_groups[[i]] %in% Focus_variables))
{
if(sum(which(var_groups[[i]] %in% Focus_variables >= 2)))
{
Intersection <- dplyr::intersect(Focus_variables, var_groups[[i]])
var_groups[[i]] <- Intersection[1]
next
}
var_groups[[i]] <- dplyr::intersect(Focus_variables, var_groups[[i]])
}
}
#Getting every combination of variables possible
if(fast_calculation == TRUE || prod(vapply(var_groups, length, 'character')) > 100)
{
result <- purrr::map(var_groups, 1)
result <- as.data.frame(t(unlist(result)))
}else
{
result <- expand.grid(var_groups)
}
RF_list <- list()
noncor_columns = colnames(Data)[! colnames(Data) %in% unlist(var_groups)]
Data_nocor <- Data[,noncor_columns, with = FALSE]
##Start of the RF, note we need to add multiprocessing here
for(i in seq(nrow(result)))
{
Data_temp <- cbind(Data_nocor, Data[, unlist(result[i,]), with = FALSE])
Rf <- ranger::ranger(as.formula(paste(paste(Y_var, '~'), paste(colnames(Data_temp), collapse = "+"))), data = Data_temp, mtry = ncol(Data_temp/3), importance = 'permutation')
Rf_2 <- data.frame(Rf$variable.importance)
RF_list[[i]] <- Rf_2
}
}else
{
Rf <- ranger(as.formula(paste(paste(Y_var, '~'), paste(colnames(Data_temp), collapse = "+"))), data = Data_temp, mtry = ncol(Data_temp/3), importance = 'permutation')
Rf_2 <- data.frame(Rf$variable.importance)
RF_list[[i]] <- Rf_2
}
for(j in seq(nrow(pairs_mat)))
{
list1[[j]] = c(pairs_mat[j,1], pairs_mat[j,2])
list1[[j]] = sort(list1[[j]])
}
i = rep(1:length(list1), lengths(list1))
j = factor(unlist(list1))
tab = Matrix::sparseMatrix(i = i , j = as.integer(j), x = TRUE, dimnames= list(NULL, levels(j)))
connects = Matrix::tcrossprod(tab, boolArith = TRUE)
group = igraph::clusters(igraph::graph_from_adjacency_matrix(as(connects, "lMatrix")))$membership
var_groups <- tapply(list1, group, function(x) sort(unique(unlist(x))))
var_groups <- as.list(var_groups)
#Condition to extract the focus variables
for(i in seq(length(var_groups)))
{
if(any(var_groups[[i]] %in% Focus_variables))
{
if(sum(which(var_groups[[i]] %in% Focus_variables >= 2)))
{
Intersection <- dplyr::intersect(Focus_variables, var_groups[[i]])
var_groups[[i]] <- Intersection[1]
next
}
var_groups[[i]] <- dplyr::intersect(Focus_variables, var_groups[[i]])
}
}
if(fast_calculation == TRUE || prod(vapply(var_groups, length, 'character')) > 100)
{
result <- purrr::map(var_groups, 1)
result <- as.data.frame(t(unlist(result)))
}else
{
result <- expand.grid(var_groups)
}
var_groups
length
vapply(var_groups, length, 'character')
vapply(var_groups, length, 'integer')
sapply(var_groups, length)
class(sapply(var_groups, length))
vapply(var_groups, length, 'integer')
prod(vapply(var_groups, length, integer)
prod(vapply(var_groups, length, integer))
prod(vapply(var_groups, length, integer))
prod(vapply(var_groups, length, integer))
prod(vapply(var_groups, length, integer))
prod(vapply(var_groups, length, integer))
prod(vapply(var_groups, length, integer))
prod(vapply(var_groups, length, integer))
prod(vapply(var_groups, length, integer))
prod(vapply(var_groups, length, integer))
prod(vapply(var_groups, length, integer))
rod(vapply(var_groups, length, vector))
prod(vapply(var_groups, length, vector))
prod(vapply(var_groups, length, 'list'))
prod(vapply(var_groups, length, 'list'))
prod(vapply(var_groups, length, 'list'))
prod(vapply(var_groups, length, 'list'))
prod(vapply(var_groups, length, 'list'))
prod(vapply(var_groups, length, 'list'))
prod(vapply(var_groups, length, 'list'))
prod(vapply(var_groups, length, 'list'))
prod(vapply(var_groups, length, 'list'))
prod(vapply(var_groups, length, 'list'))
prod(vapply(var_groups, length, 'list'))
prod(vapply(var_groups, length, 'integer'[1]))
prod(vapply(var_groups, length, 'integer[1]'))
class(sapply(var_groups, length))
vapply(var_groups, length, 'integer')
vapply(var_groups, length, 'integer')
vapply(var_groups, length, length(var_groups))
#Getting every combination of variables possible
if(fast_calculation == TRUE || prod(vapply(var_groups, length, length(var_groups)) > 100))
{
result <- purrr::map(var_groups, 1)
result <- as.data.frame(t(unlist(result)))
}else
{
result <- expand.grid(var_groups)
}
fast_calculation == TRUE || prod(vapply(var_groups, length, length(var_groups)) > 100)
prod(vapply(var_groups, length, length(var_groups))
fast_calculation == TRUE || prod(vapply(var_groups, length, length(var_groups))) > 100)
fast_calculation == TRUE || prod(vapply(var_groups, length, length(var_groups))) > 100)
fast_calculation == TRUE || prod(vapply(var_groups, length, length(var_groups))) > 100)
fast_calculation == TRUE || prod(vapply(var_groups, length, length(var_groups))) > 100)
fast_calculation == TRUE || prod(vapply(var_groups, length, length(var_groups))) > 100)
fast_calculation == TRUE || prod(vapply(var_groups, length, length(var_groups))) > 100)
prod(vapply(var_groups, length, length(var_groups)))
prod(vapply(var_groups, length, length(var_groups))) > 100
fast_calculation == TRUE || prod(vapply(var_groups, length, length(var_groups))) > 100
#Getting every combination of variables possible
if(fast_calculation == TRUE || prod(vapply(var_groups, length, length(var_groups))) > 100)
{
result <- purrr::map(var_groups, 1)
result <- as.data.frame(t(unlist(result)))
}else
{
result <- expand.grid(var_groups)
}
noncor_columns = colnames(Data)[! colnames(Data) %in% unlist(var_groups)]
Data_nocor <- Data[,noncor_columns, with = FALSE]
##Start of the RF, note we need to add multiprocessing here
for(i in seq(nrow(result)))
{
Data_temp <- cbind(Data_nocor, Data[, unlist(result[i,]), with = FALSE])
Rf <- ranger::ranger(as.formula(paste(paste(Y_var, '~'), paste(colnames(Data_temp), collapse = "+"))), data = Data_temp, mtry = ncol(Data_temp/3), importance = 'permutation')
Rf_2 <- data.frame(Rf$variable.importance)
RF_list[[i]] <- Rf_2
}
RF_list <- list()
for(i in seq(nrow(result)))
{
Data_temp <- cbind(Data_nocor, Data[, unlist(result[i,]), with = FALSE])
Rf <- ranger::ranger(as.formula(paste(paste(Y_var, '~'), paste(colnames(Data_temp), collapse = "+"))), data = Data_temp, mtry = ncol(Data_temp/3), importance = 'permutation')
Rf_2 <- data.frame(Rf$variable.importance)
RF_list[[i]] <- Rf_2
}
library(TangledFeatures)
devtools::document()
devtools::build_vignettes(clean = TRUE)
devtools::test()
devtools::check()
devtools::build()
goodpractice::gp()
library(TangledFeatures)
